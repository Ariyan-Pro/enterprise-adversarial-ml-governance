
        <!DOCTYPE html>
        <html lang="en">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Adversarial ML Security Assessment</title>
            <style>
                body {
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
                    line-height: 1.6;
                    color: #333;
                    max-width: 1200px;
                    margin: 0 auto;
                    padding: 20px;
                }
                h1, h2, h3 {
                    color: #2E5A88;
                    border-bottom: 2px solid #4A6FA5;
                    padding-bottom: 10px;
                }
                table {
                    border-collapse: collapse;
                    width: 100%;
                    margin: 20px 0;
                }
                th, td {
                    border: 1px solid #ddd;
                    padding: 12px;
                    text-align: left;
                }
                th {
                    background-color: #4A6FA5;
                    color: white;
                }
                tr:nth-child(even) {
                    background-color: #f9f9f9;
                }
                .header {
                    background: linear-gradient(135deg, #2E5A88, #4A6FA5);
                    color: white;
                    padding: 30px;
                    border-radius: 10px;
                    margin-bottom: 30px;
                }
                .footer {
                    margin-top: 50px;
                    padding-top: 20px;
                    border-top: 2px solid #ddd;
                    color: #666;
                    font-size: 0.9em;
                }
                .visualization {
                    margin: 30px 0;
                    text-align: center;
                }
                .visualization img {
                    max-width: 100%;
                    height: auto;
                    border: 1px solid #ddd;
                    border-radius: 5px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }
                .recommendation {
                    background-color: #f0f7ff;
                    border-left: 4px solid #4A6FA5;
                    padding: 15px;
                    margin: 15px 0;
                }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Adversarial ML Security Assessment Report</h1>
                <p>Generated: 2026-01-10 14:50:03</p>
            </div>
            
            <div class="content">
                <h1>EXECUTIVE SUMMARY</h1>
<h2>Project Overview</h2>
<p>This report summarizes the security assessment of the MNIST CNN model 
against various adversarial attacks and evaluates the effectiveness of 
multiple defense mechanisms.</p>
<h2>Key Findings</h2>
<h2>Risk Assessment</h2>
<ul>
<li><strong>Critical Risk:</strong> High susceptibility to PGD attacks</li>
<li><strong>Medium Risk:</strong> Moderate vulnerability to FGSM attacks</li>
<li><strong>Low Risk:</strong> Good robustness against simple perturbations</li>
</ul>
<h2>Recommendations</h2>
<ol>
<li>Implement adversarial training for critical deployments</li>
<li>Use input smoothing as a lightweight defense</li>
<li>Deploy ensemble models for high-security applications</li>
<li>Regular security audits and adversarial testing</li>
</ol>
<h1>MODEL PERFORMANCE</h1>
<h2>Baseline Model</h2>
<ul>
<li><strong>Model Architecture:</strong> MNIST CNN</li>
<li><strong>Total Parameters:</strong> 207018</li>
<li><strong>Input Dimensions:</strong> 28x28</li>
<li><strong>Number of Classes:</strong> 10</li>
</ul>
<h1>ATTACK ANALYSIS</h1>
<h2>Overview of Evaluated Attacks</h2>
<ul>
<li><strong>FGSM:</strong> Fast Gradient Sign Method: Single-step attack using gradient sign</li>
<li><strong>PGD:</strong> Projected Gradient Descent: Iterative attack with projection</li>
<li><strong>DEEPFOOL:</strong> DeepFool: Minimal perturbation attack for misclassification</li>
</ul>
<h1>DEFENSE EVALUATION</h1>
<h2>Overview of Evaluated Defenses</h2>
<ul>
<li><strong>Adversarial Training:</strong> Trains model on adversarial examples to improve robustness</li>
<li><strong>Input Smoothing:</strong> Applies smoothing filters to input images to reduce perturbations</li>
<li><strong>Randomized Transform:</strong> Applies random transformations to break adversarial patterns</li>
<li><strong>Ensemble:</strong> Uses multiple models to make predictions, increasing robustness</li>
</ul>
<h1>RECOMMENDATIONS</h1>
<h2>Based on Evaluation Results</h2>
            </div>
            
            <div class="footer">
                <p>Generated by Adversarial ML Security Suite | Confidential</p>
                <p>This report contains sensitive security information. Handle with appropriate confidentiality measures.</p>
            </div>
        </body>
        </html>
        